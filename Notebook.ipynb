{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "crO-tLv3HGAh",
        "S1iZvYbv4IT3",
        "DGLo-iPUkaQX",
        "ynaLSZpFkoir",
        "RODdiQ4RH5J3",
        "mGtxt4lt4LUD",
        "PbLHuS4Gr4ht",
        "m9Zt_j9L4PE6"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rafio-iut/Vegetable-Classification-and-Quality-Assessment/blob/grad-cam/Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize Environment"
      ],
      "metadata": {
        "id": "S1iZvYbv4IT3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Packages"
      ],
      "metadata": {
        "id": "YYJtphtdrRP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "id": "ztf8q74QrUeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "crO-tLv3HGAh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import Subset\n",
        "from torch.utils.data import ConcatDataset\n",
        "from torch.utils.data import random_split\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import models, transforms\n",
        "from torchsummary import summary\n",
        "\n",
        "import math\n",
        "import time\n",
        "import random\n",
        "import os\n",
        "import shutil\n",
        "import copy\n",
        "import dotenv"
      ],
      "metadata": {
        "id": "xdquQAzqHLSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Seed"
      ],
      "metadata": {
        "id": "bbjuewK7V51H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_state = 112\n",
        "\n",
        "random = random.Random(random_state)\n",
        "torch.manual_seed(random_state)"
      ],
      "metadata": {
        "id": "_JLEyJ4dVtHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup GPU"
      ],
      "metadata": {
        "id": "docDP771Hh45"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfcW42KY-wQo"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Environment Variables"
      ],
      "metadata": {
        "id": "h_EzemhKrnwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dotenv.load_dotenv('.env')\n",
        "github_token = os.getenv('GITHUB_TOKEN')"
      ],
      "metadata": {
        "id": "gq9brsGArs5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone Repository"
      ],
      "metadata": {
        "id": "ESfEumvpEJz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r *\n",
        "!git clone https://{github_token}@github.com/rafio-iut/Vegetable-Classification-and-Quality-Assessment.git\n",
        "!mv Vegetable-Classification-and-Quality-Assessment/* .\n",
        "!rm -r Vegetable-Classification-and-Quality-Assessment"
      ],
      "metadata": {
        "id": "chWik_MeEPGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explode Directories"
      ],
      "metadata": {
        "id": "DGLo-iPUkaQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = \"/content/New VegNet\"\n",
        "\n",
        "for folder_name in os.listdir(root_dir):\n",
        "    folder_path = os.path.join(root_dir, folder_name)\n",
        "\n",
        "    if os.path.isdir(folder_path):\n",
        "        for subfolder_name in os.listdir(folder_path):\n",
        "            subfolder_path = os.path.join(folder_path, subfolder_name)\n",
        "\n",
        "            if os.path.isdir(subfolder_path):\n",
        "                new_folder_name = folder_name + \" - \" + subfolder_name\n",
        "                new_folder_name = new_folder_name.split(\". \")[1]\n",
        "                new_folder_path = os.path.join(root_dir, new_folder_name)\n",
        "\n",
        "                os.makedirs(new_folder_path, exist_ok=True)\n",
        "\n",
        "                for file_name in os.listdir(subfolder_path):\n",
        "                    file_path = os.path.join(subfolder_path, file_name)\n",
        "                    new_file_path = os.path.join(new_folder_path, file_name)\n",
        "                    shutil.move(file_path, new_file_path)\n",
        "\n",
        "                os.rmdir(subfolder_path)"
      ],
      "metadata": {
        "id": "RqkgvcedkdSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Delete Empty Folders"
      ],
      "metadata": {
        "id": "ynaLSZpFkoir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = '/content/New VegNet'\n",
        "\n",
        "for root, dirs, files in os.walk(root_dir, topdown=False):\n",
        "        for folder in dirs:\n",
        "            folder_path = os.path.join(root, folder)\n",
        "            if not os.listdir(folder_path):\n",
        "                os.rmdir(folder_path)"
      ],
      "metadata": {
        "id": "A4DOSgW1kquh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Default Options"
      ],
      "metadata": {
        "id": "VP4avuXMUNMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skip_count = False"
      ],
      "metadata": {
        "id": "NuzzThHjUPfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modified Options"
      ],
      "metadata": {
        "id": "7ItsnCgSG2yW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skip_count = True"
      ],
      "metadata": {
        "id": "3xK3T-PuG5YF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Data"
      ],
      "metadata": {
        "id": "RODdiQ4RH5J3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Raw Dataset"
      ],
      "metadata": {
        "id": "mGtxt4lt4LUD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KjQgEkEbFa_"
      },
      "outputs": [],
      "source": [
        "root_dir = '/content/New VegNet'\n",
        "\n",
        "raw_dataset = torchvision.datasets.ImageFolder(root=root_dir, transform=transforms.ToTensor())\n",
        "all_labels = raw_dataset.classes\n",
        "\n",
        "print(all_labels)\n",
        "print(len(raw_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_label(label):\n",
        "    words = label.split(\" - \")\n",
        "    if len(words) < 2: return None, None\n",
        "    vegetable = words[0].strip()\n",
        "    quality = words[1].strip()\n",
        "    return vegetable, quality"
      ],
      "metadata": {
        "id": "dhiZR_2UsAAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_vegetables = []\n",
        "all_qualities = []\n",
        "\n",
        "for label in all_labels:\n",
        "    vegetable, quality = parse_label(label)\n",
        "    if vegetable not in all_vegetables: all_vegetables.append(vegetable)\n",
        "    if quality not in all_qualities: all_qualities.append(quality)\n",
        "\n",
        "all_vegetables = sorted(all_vegetables)\n",
        "all_qualities = sorted(all_qualities)\n",
        "\n",
        "print(all_vegetables)\n",
        "print(all_qualities)"
      ],
      "metadata": {
        "id": "yAzgV8Gk3kFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Shuffle Dataset"
      ],
      "metadata": {
        "id": "MA8C5WLWt9tq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = len(raw_dataset)\n",
        "shuffle_indices = list(range(num_samples))\n",
        "random.shuffle(shuffle_indices)\n",
        "print(shuffle_indices[:10])\n",
        "\n",
        "raw_dataset = Subset(raw_dataset, shuffle_indices)"
      ],
      "metadata": {
        "id": "Cth-0L6XuAZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Display Dataset"
      ],
      "metadata": {
        "id": "PbLHuS4Gr4ht"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility Functions"
      ],
      "metadata": {
        "id": "J9s80_eIp5MT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_label_counts(dataset):\n",
        "    targets = [target for _, target in dataset]\n",
        "\n",
        "    counts = {}\n",
        "    for target in targets:\n",
        "        label = all_labels[target]\n",
        "        if label in counts: counts[label] += 1\n",
        "        else: counts[label] = 1\n",
        "\n",
        "    return dict(sorted(counts.items()))\n",
        "\n",
        "def get_label_images(dataset):\n",
        "    label_images = {}\n",
        "    for image, target in dataset:\n",
        "        label = all_labels[target]\n",
        "        if label not in label_images:\n",
        "            label_images[label] = image\n",
        "            if len(label_images) == len(all_labels): return dict(sorted(label_images.items()))\n",
        "\n",
        "    return dict(sorted(label_images.items()))"
      ],
      "metadata": {
        "id": "oXSvp5-qZ72O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_counts(dataset, dataset_name):\n",
        "    if skip_count: return\n",
        "    label_counts = get_label_counts(dataset)\n",
        "\n",
        "    df_table = pd.DataFrame(index=all_vegetables, columns=all_qualities)\n",
        "    df_table.fillna(0, inplace=True)\n",
        "\n",
        "    for label, count in label_counts.items():\n",
        "        vegetable, quality = parse_label(label)\n",
        "        df_table.loc[vegetable, quality] = count\n",
        "\n",
        "    df_table.loc['Total'] = df_table.sum()\n",
        "    df_table['Total'] = df_table.sum(axis=1)\n",
        "\n",
        "    print(dataset_name)\n",
        "    display(df_table)\n",
        "    print()"
      ],
      "metadata": {
        "id": "_-ddtAe-YmrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_images(dataset, dataset_name):\n",
        "    label_images = get_label_images(dataset)\n",
        "\n",
        "    num_classes = len(label_images)\n",
        "    num_cols = 5\n",
        "    num_rows = math.ceil(num_classes / num_cols)\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 4*num_rows))\n",
        "\n",
        "    for i, (label, image) in enumerate(label_images.items()):\n",
        "        row = i // num_cols\n",
        "        col = i % num_cols\n",
        "\n",
        "        image = image.numpy().transpose(1, 2, 0)\n",
        "        vegetable, quality = parse_label(label)\n",
        "\n",
        "        ax = axes[row, col] if num_rows > 1 else axes[col]\n",
        "        ax.imshow(image)\n",
        "        ax.set_title(vegetable, fontsize=12, fontweight='bold', pad=10)\n",
        "        ax.axis('off')\n",
        "        ax.text(0.5, -0.075, quality, transform=ax.transAxes, ha='center', fontsize=12)\n",
        "\n",
        "    for i in range(len(label_images), num_rows * num_cols):\n",
        "        row = i // num_cols\n",
        "        col = i % num_cols\n",
        "\n",
        "        ax = axes[row, col] if num_rows > 1 else axes[col]\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.tight_layout(h_pad=2)\n",
        "    print(dataset_name)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "6mSUktid0VK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display Counts"
      ],
      "metadata": {
        "id": "vZ4BotTYqK2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display_counts(raw_dataset, 'Raw Dataset')"
      ],
      "metadata": {
        "id": "o-ReC-9-I4uV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display Images"
      ],
      "metadata": {
        "id": "ne_htMsfqOo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display_images(raw_dataset, 'Raw Dataset')"
      ],
      "metadata": {
        "id": "oDjE8h6yI46w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Transformation"
      ],
      "metadata": {
        "id": "xOJX5ZPV5f1T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Transformations"
      ],
      "metadata": {
        "id": "afbGxyKl6a-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformations = [\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.4, contrast=0.4),\n",
        "    transforms.RandomAffine(degrees=0, shear=10),\n",
        "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
        "    transforms.RandomAffine(degrees=0, scale=(0.9, 1.1)),\n",
        "    transforms.ToTensor()\n",
        "]\n",
        "\n",
        "display_transformations = {\n",
        "    'Random Rotation': transformations[0],\n",
        "    'Random Horizontal Flip': transforms.RandomHorizontalFlip(1.0),\n",
        "    'Random Vertical Flip': transforms.RandomVerticalFlip(1.0),\n",
        "    'Random Jitter': transformations[3],\n",
        "    'Random Shear': transformations[4],\n",
        "    'Random Shift': transformations[5],\n",
        "    'Random Scale': transformations[6]\n",
        "}"
      ],
      "metadata": {
        "id": "AjUFcUfWzYuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display Transformations"
      ],
      "metadata": {
        "id": "HxrOA-pY3mYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_index = random.randint(0, len(raw_dataset)-1)\n",
        "sample_image, _ = raw_dataset[random_index]\n",
        "\n",
        "num_transformations = len(display_transformations)\n",
        "num_cols = 4\n",
        "num_rows = math.ceil(num_transformations / num_cols)\n",
        "\n",
        "fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 5*num_rows))\n",
        "\n",
        "image = sample_image.numpy().transpose(1, 2, 0)\n",
        "axes[0, 0].imshow(image)\n",
        "axes[0, 0].set_title('Original')\n",
        "\n",
        "for i, (title, transform) in enumerate(display_transformations.items()):\n",
        "    transformed_image = transform(sample_image)\n",
        "    image = transformed_image.numpy().transpose(1, 2, 0)\n",
        "    row = (i + 1) // num_cols\n",
        "    col = (i + 1) % num_cols\n",
        "    axes[row, col].imshow(image)\n",
        "    axes[row, col].set_title(title)\n",
        "\n",
        "for i in range(num_transformations + 1, num_rows * num_cols):\n",
        "    row = i // num_cols\n",
        "    col = i % num_cols\n",
        "    axes[row, col].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CghqC0pP38Vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Transformed Dataset"
      ],
      "metadata": {
        "id": "bSSMH7aj61S3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformedDataset(Dataset):\n",
        "    def __init__(self, dataset, transform):\n",
        "        if isinstance(dataset, Subset):\n",
        "            self.dataset = dataset.dataset\n",
        "            self.indices = dataset.indices\n",
        "        else:\n",
        "            self.dataset = dataset\n",
        "            self.indices = range(len(dataset))\n",
        "\n",
        "        self.transform = transform\n",
        "        self.to_pil = transforms.ToPILImage()\n",
        "\n",
        "        original_attrs = vars(self.dataset)\n",
        "        for attr_name, attr_value in original_attrs.items():\n",
        "            if not hasattr(self, attr_name):\n",
        "                setattr(self, attr_name, attr_value)\n",
        "\n",
        "        original_methods = [method_name for method_name in dir(self.dataset) if callable(getattr(self.dataset, method_name))]\n",
        "        for method_name in original_methods:\n",
        "            if not hasattr(self, method_name):\n",
        "                method = getattr(self.dataset, method_name)\n",
        "                setattr(self, method_name, method)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image, label = self.dataset[self.indices[index]]\n",
        "        image = self.to_pil(image)\n",
        "        transformed_image = self.transform(image)\n",
        "        return transformed_image, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "transformed_dataset = TransformedDataset(raw_dataset, transforms.Compose(transformations))"
      ],
      "metadata": {
        "id": "PZL1apv063oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display Dataset"
      ],
      "metadata": {
        "id": "N_Z-yBIa7BjE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display_counts(transformed_dataset, 'Transformed Dataset')\n",
        "display_images(transformed_dataset, 'Transformed Dataset')"
      ],
      "metadata": {
        "id": "QTr2r0WH7E_c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-Fold Cross Validation"
      ],
      "metadata": {
        "id": "m9Zt_j9L4PE6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility Functions"
      ],
      "metadata": {
        "id": "MreHWHmt7SKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def balance_classes(dataset):\n",
        "    if isinstance(dataset, Subset):\n",
        "        original_dataset = dataset.dataset\n",
        "        dataset_indices = dataset.indices\n",
        "    else:\n",
        "        original_dataset = dataset\n",
        "        dataset_indices = range(len(dataset))\n",
        "\n",
        "    num_classes = len(original_dataset.classes)\n",
        "    class_indices = [[] for _ in range(num_classes)]\n",
        "    class_counts = [0] * num_classes\n",
        "\n",
        "    for index in dataset_indices:\n",
        "        _, target = original_dataset[index]\n",
        "        class_indices[target].append(index)\n",
        "        class_counts[target] += 1\n",
        "\n",
        "    max_count = max(class_counts)\n",
        "\n",
        "    duplicates = []\n",
        "\n",
        "    for target, count in enumerate(class_counts):\n",
        "        while count < max_count:\n",
        "            duplicate_index = random.choice(class_indices[target])\n",
        "            duplicates.append(duplicate_index)\n",
        "            count += 1\n",
        "\n",
        "    balanced_indices = list(dataset_indices) + duplicates\n",
        "    balanced_dataset = Subset(original_dataset, balanced_indices)\n",
        "\n",
        "    return balanced_dataset\n",
        "\n",
        "def generate_subsets(dataset, k):\n",
        "    if isinstance(dataset, Subset):\n",
        "        original_dataset = dataset.dataset\n",
        "        dataset_indices = dataset.indices\n",
        "    else:\n",
        "        original_dataset = dataset\n",
        "        dataset_indices = range(len(dataset))\n",
        "\n",
        "    num_classes = len(original_dataset.classes)\n",
        "    class_indices = [[] for _ in range(num_classes)]\n",
        "    class_counts = [0] * num_classes\n",
        "\n",
        "    subset_class_counts = [[0] * k for _ in range(num_classes)]\n",
        "    subset_indices = [[] for _ in range(k)]\n",
        "    subsets = []\n",
        "\n",
        "    for index in dataset_indices:\n",
        "        _, target = original_dataset[index]\n",
        "        target_counts = subset_class_counts[target]\n",
        "\n",
        "        candidate_subsets = []\n",
        "        for i in range(k):\n",
        "            if len(candidate_subsets) == 0: candidate_subsets.append(i)\n",
        "            else:\n",
        "                min_count = target_counts[candidate_subsets[0]]\n",
        "                if target_counts[i] == min_count: candidate_subsets.append(i)\n",
        "                elif target_counts[i] < min_count: candidate_subsets = [i]\n",
        "\n",
        "        selected_subset = random.choice(candidate_subsets)\n",
        "        subset_indices[selected_subset].append(index)\n",
        "        subset_class_counts[target][selected_subset] += 1\n",
        "\n",
        "    for indices in subset_indices:\n",
        "        random.shuffle(indices)\n",
        "        subsets.append(Subset(original_dataset, indices))\n",
        "\n",
        "    return subsets"
      ],
      "metadata": {
        "id": "4r5MCrCR7WI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Subsets"
      ],
      "metadata": {
        "id": "-Dgwhy699rUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = 5\n",
        "plain_subset = generate_subsets(transformed_dataset, k)\n",
        "\n",
        "balanced_subset = []\n",
        "for i in range(k): balanced_subset.append(balance_classes(plain_subset[i]))"
      ],
      "metadata": {
        "id": "2c44Os377SXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, subset in enumerate(plain_subset): display_counts(subset, f'Subset {i+1}')\n",
        "for i, subset in enumerate(balanced_subset): display_counts(subset, f'Balanced Subset {i+1}')"
      ],
      "metadata": {
        "id": "emoSNP4cim3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_splits(plain_subset, balanced_subset, test_index):\n",
        "    data_split = {}\n",
        "\n",
        "    testset = plain_subset[test_index].dataset.dataset\n",
        "    trainvalset = ConcatDataset(balanced_subset[:test_index] + balanced_subset[test_index+1:])\n",
        "\n",
        "    train_size = int(0.8 * len(trainvalset))\n",
        "    val_size = len(trainvalset) - train_size\n",
        "    trainset, valset = random_split(trainvalset, [train_size, val_size])\n",
        "\n",
        "    data_split['Train'] = trainset\n",
        "    data_split['Val'] = valset\n",
        "    data_split['Test'] = testset\n",
        "    for phase in ['Train', 'Val', 'Test']: display_counts(data_split[phase], f'{phase}-set {test_index + 1}')\n",
        "\n",
        "    return data_split"
      ],
      "metadata": {
        "id": "_CWw67psLWID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare Data Loaders"
      ],
      "metadata": {
        "id": "1HQWHMFkLBxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = 5\n",
        "data_splits = []\n",
        "dataloaders = []\n",
        "\n",
        "for i in range(k):\n",
        "    print(f'Preparing Test {i+1}')\n",
        "    print('-' * 20)\n",
        "    print()\n",
        "\n",
        "    split = get_data_splits(plain_subset, balanced_subset, i)\n",
        "    loader = {x: torch.utils.data.DataLoader(split[x], batch_size=32, shuffle=True, num_workers=2)\n",
        "                      for x in ['Train', 'Val', 'Test']}\n",
        "    data_splits.append(split)\n",
        "    dataloaders.append(loader)"
      ],
      "metadata": {
        "id": "04pBDjjpBNeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display a Data Split"
      ],
      "metadata": {
        "id": "FceSP8eOm77e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "display_images(data_splits[0]['Train'], 'Train-set 1')\n",
        "display_images(data_splits[0]['Val'], 'Val-set 1')\n",
        "display_images(data_splits[0]['Test'], 'Test-set 1')"
      ],
      "metadata": {
        "id": "IJfWXkHlm93Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Models"
      ],
      "metadata": {
        "id": "tRgl0g5z7Nqt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility Functions"
      ],
      "metadata": {
        "id": "LPzIhqBRIYxj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_step(data_split, dataloader, model, preprocess, criterion, optimizer, phase):\n",
        "    running_loss = 0.0\n",
        "    correct_counts = 0\n",
        "\n",
        "    for batch_image, batch_target in dataloader[phase]:\n",
        "        batch_image = [preprocess(image) for image in batch_image]\n",
        "        batch_image = torch.stack(batch_image)\n",
        "        batch_image = batch_image.to(device)\n",
        "        batch_target = batch_target.to(device)\n",
        "\n",
        "        with torch.set_grad_enabled(phase == 'Train'):\n",
        "            batch_probabilities = model(batch_image)\n",
        "            _, batch_prediction = torch.max(batch_probabilities, 1)\n",
        "            loss = criterion(batch_probabilities, batch_target)\n",
        "\n",
        "            if phase == 'Train':\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * batch_image.size(0)\n",
        "        correct_counts += torch.sum(batch_prediction == batch_target)\n",
        "\n",
        "    step_loss = running_loss / len(data_split[phase])\n",
        "    step_acc = correct_counts.double() / len(data_split[phase])\n",
        "\n",
        "    return step_loss, step_acc\n",
        "\n",
        "def train_model(data_split, dataloader, model, preprocess, hyperparameters):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    criterion, learning_rate, momentum, scheduler_step_size, gamma, patience = (\n",
        "        hyperparameters['loss_function'],\n",
        "        hyperparameters['learning_rate'],\n",
        "        hyperparameters['momentum'],\n",
        "        hyperparameters['scheduler_step_size'],\n",
        "        hyperparameters['gamma'],\n",
        "        hyperparameters['patience']\n",
        "    )\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step_size, gamma=gamma)\n",
        "    num_epochs = hyperparameters.get('num_epochs', 1)\n",
        "\n",
        "    counter = 0\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1, 1):\n",
        "        print(f'Running Epoch {epoch}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['Train', 'Val']:\n",
        "            if phase == 'Train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            step_loss, step_acc = run_step(data_split, dataloader, model, preprocess, criterion, optimizer, phase)\n",
        "            print(f'{phase} Loss: {step_loss:.4f}, Acc: {step_acc:.2%}')\n",
        "\n",
        "            if phase == 'Val':\n",
        "                if step_acc > best_acc:\n",
        "                    best_acc = step_acc\n",
        "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                    counter = 0\n",
        "                else:\n",
        "                    counter += 1\n",
        "                    if best_acc==1 or counter >= patience: break\n",
        "\n",
        "        if phase == 'Train': scheduler.step()\n",
        "        if best_acc==1 or counter >= patience:\n",
        "            print(f'Convergence reached after {epoch} epochs.')\n",
        "            print('Stopping Training')\n",
        "            print('-' * 10)\n",
        "            break\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'\\nTraining complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Best val Acc: {best_acc * 100:.2f}%')\n",
        "    print()\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "def train_model_kfold(model_name, model, preprocess, k=5, hyperparameters=None):\n",
        "    base_state = copy.deepcopy(model.state_dict())\n",
        "    trained_models = []\n",
        "\n",
        "    for test_index in range(k):\n",
        "        model.load_state_dict(base_state)\n",
        "        print(f'Training {model_name} for Test {test_index + 1}')\n",
        "        print('-' * 20)\n",
        "        print()\n",
        "\n",
        "        data_split = data_splits[test_index]\n",
        "        dataloader = dataloaders[test_index]\n",
        "\n",
        "        model = train_model(data_split, dataloader, model, preprocess, hyperparameters)\n",
        "        trained_models.append(copy.deepcopy(model))\n",
        "\n",
        "    return trained_models"
      ],
      "metadata": {
        "id": "Ln41e62JIlfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Training"
      ],
      "metadata": {
        "id": "EG0U-TN6Ok67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_output(model, preprocess, image_tensor):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        image = preprocess(image_tensor)\n",
        "        image = image.unsqueeze(0).to(device)\n",
        "\n",
        "        probabilities = model(image)\n",
        "        _, prediction = torch.max(probabilities, 1)\n",
        "\n",
        "        prediction = prediction.item()\n",
        "        probabilities = probabilities.squeeze().detach().cpu().numpy()\n",
        "\n",
        "    return prediction, probabilities"
      ],
      "metadata": {
        "id": "GRsuZS0EWAMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completed_model_sets = []"
      ],
      "metadata": {
        "id": "yrl39KnbapoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AlexNet"
      ],
      "metadata": {
        "id": "XILlJiAkcK92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'AlexNet'\n",
        "weights = models.AlexNet_Weights.IMAGENET1K_V1\n",
        "model = models.alexnet(weights=weights)\n",
        "preprocess = weights.transforms(antialias=None)\n",
        "\n",
        "model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, len(all_labels))\n",
        "model = model.to(device)\n",
        "\n",
        "crop_size = preprocess.crop_size[0]\n",
        "input_size = (3, crop_size, crop_size)\n",
        "summary(model, input_size)"
      ],
      "metadata": {
        "id": "t412dRSCcK-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters = {\n",
        "#     'loss_function': nn.CrossEntropyLoss(),\n",
        "#     'learning_rate': 0.001,\n",
        "#     'momentum': 0.9,\n",
        "#     'scheduler_step_size': 7,\n",
        "#     'gamma': 0.1,\n",
        "#     'num_epochs': 2,\n",
        "#     'patience': 10\n",
        "# }\n",
        "\n",
        "# trained_models = train_model_kfold(model_name, model, preprocess, k=5, hyperparameters=hyperparameters)\n",
        "\n",
        "# completed_model_sets.append(\n",
        "#     {\n",
        "#         'name': model_name,\n",
        "#         'preprocess': preprocess,\n",
        "#         'models': trained_models\n",
        "#     }\n",
        "# )"
      ],
      "metadata": {
        "id": "EXE6q6IU23AL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet-50"
      ],
      "metadata": {
        "id": "05TuWOQpZmoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'ResNet-50'\n",
        "weights = models.ResNet50_Weights.IMAGENET1K_V2\n",
        "model = models.resnet50(weights=weights)\n",
        "preprocess = weights.transforms(antialias=None)\n",
        "\n",
        "model.fc = nn.Linear(model.fc.in_features, len(all_labels))\n",
        "model = model.to(device)\n",
        "\n",
        "crop_size = preprocess.crop_size[0]\n",
        "input_size = (3, crop_size, crop_size)\n",
        "summary(model, input_size)"
      ],
      "metadata": {
        "id": "dMLDb7a9IYdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters = {\n",
        "#     'loss_function': nn.CrossEntropyLoss(),\n",
        "#     'learning_rate': 0.001,\n",
        "#     'momentum': 0.9,\n",
        "#     'scheduler_step_size': 7,\n",
        "#     'gamma': 0.1,\n",
        "#     'num_epochs': 1,\n",
        "#     'patience': 10\n",
        "# }\n",
        "\n",
        "# trained_models = train_model_kfold(model_name, model, preprocess, k=5, hyperparameters=hyperparameters)\n",
        "\n",
        "# completed_model_sets.append(\n",
        "#     {\n",
        "#         'name': model_name,\n",
        "#         'preprocess': preprocess,\n",
        "#         'models': trained_models\n",
        "#     }\n",
        "# )"
      ],
      "metadata": {
        "id": "6dtwUDxZWWvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DenseNet-169"
      ],
      "metadata": {
        "id": "3sGrIk0ohg8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'DenseNet-169'\n",
        "weights = models.DenseNet169_Weights.IMAGENET1K_V1\n",
        "model = models.densenet169(weights=weights)\n",
        "preprocess = weights.transforms(antialias=None)\n",
        "\n",
        "model.classifier = nn.Linear(model.classifier.in_features, len(all_labels))\n",
        "model = model.to(device)\n",
        "\n",
        "# crop_size = preprocess.crop_size[0]\n",
        "# input_size = (3, crop_size, crop_size)\n",
        "# summary(model, input_size)"
      ],
      "metadata": {
        "id": "-WfsLd_4hg8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparameters = {\n",
        "    'loss_function': nn.CrossEntropyLoss(),\n",
        "    'learning_rate': 0.001,\n",
        "    'momentum': 0.9,\n",
        "    'scheduler_step_size': 7,\n",
        "    'gamma': 0.1,\n",
        "    'num_epochs': 1,\n",
        "    'patience': 10\n",
        "}\n",
        "\n",
        "trained_models = train_model_kfold(model_name, model, preprocess, k=5, hyperparameters=hyperparameters)\n",
        "\n",
        "completed_model_sets.append(\n",
        "    {\n",
        "        'name': model_name,\n",
        "        'preprocess': preprocess,\n",
        "        'models': trained_models\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "C2fuxO4SeRS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VGG-16"
      ],
      "metadata": {
        "id": "FAIrIzbf9mhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'VGG-16'\n",
        "weights = models.VGG16_Weights.IMAGENET1K_V1\n",
        "model = models.vgg16(weights=weights)\n",
        "preprocess = weights.transforms(antialias=None)\n",
        "\n",
        "model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, len(all_labels))\n",
        "model = model.to(device)\n",
        "\n",
        "crop_size = preprocess.crop_size[0]\n",
        "input_size = (3, crop_size, crop_size)\n",
        "summary(model, input_size)"
      ],
      "metadata": {
        "id": "XjwRjVs29mhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters = {\n",
        "#     'loss_function': nn.CrossEntropyLoss(),\n",
        "#     'learning_rate': 0.001,\n",
        "#     'momentum': 0.9,\n",
        "#     'scheduler_step_size': 7,\n",
        "#     'gamma': 0.1,\n",
        "#     'num_epochs': 1,\n",
        "#     'patience': 10\n",
        "# }\n",
        "\n",
        "# trained_models = train_model_kfold(model_name, model, preprocess, k=5, hyperparameters=hyperparameters)\n",
        "\n",
        "# completed_model_sets.append(\n",
        "#     {\n",
        "#         'name': model_name,\n",
        "#         'preprocess': preprocess,\n",
        "#         'models': trained_models\n",
        "#     }\n",
        "# )"
      ],
      "metadata": {
        "id": "wXwswdeGeT8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### EfficientNetV2-S"
      ],
      "metadata": {
        "id": "DGYbPDBz-7mB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'EfficientNetV2-S'\n",
        "weights = models.EfficientNet_V2_S_Weights.IMAGENET1K_V1\n",
        "model = models.efficientnet_v2_s(weights=weights)\n",
        "preprocess = weights.transforms(antialias=None)\n",
        "\n",
        "model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, len(all_labels))\n",
        "model = model.to(device)\n",
        "\n",
        "crop_size = preprocess.crop_size[0]\n",
        "input_size = (3, crop_size, crop_size)\n",
        "summary(model, input_size)"
      ],
      "metadata": {
        "id": "Fx7CgiVG-7mK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters = {\n",
        "#     'loss_function': nn.CrossEntropyLoss(),\n",
        "#     'learning_rate': 0.001,\n",
        "#     'momentum': 0.9,\n",
        "#     'scheduler_step_size': 7,\n",
        "#     'gamma': 0.1,\n",
        "#     'num_epochs': 1,\n",
        "#     'patience': 10\n",
        "# }\n",
        "\n",
        "# trained_models = train_model_kfold(model_name, model, preprocess, k=5, hyperparameters=hyperparameters)\n",
        "\n",
        "# completed_model_sets.append(\n",
        "#     {\n",
        "#         'name': model_name,\n",
        "#         'preprocess': preprocess,\n",
        "#         'models': trained_models\n",
        "#     }\n",
        "# )"
      ],
      "metadata": {
        "id": "_4cS898aedyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MobileNetV3"
      ],
      "metadata": {
        "id": "worzKFkvFYoo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'MobileNetV3'\n",
        "weights = models.MobileNet_V3_Large_Weights.IMAGENET1K_V2\n",
        "model = models.mobilenet_v3_large(weights=weights)\n",
        "preprocess = weights.transforms(antialias=None)\n",
        "\n",
        "model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, len(all_labels))\n",
        "model = model.to(device)\n",
        "\n",
        "crop_size = preprocess.crop_size[0]\n",
        "input_size = (3, crop_size, crop_size)\n",
        "summary(model, input_size)"
      ],
      "metadata": {
        "id": "kwiW0ghaFYow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters = {\n",
        "#     'loss_function': nn.CrossEntropyLoss(),\n",
        "#     'learning_rate': 0.001,\n",
        "#     'momentum': 0.9,\n",
        "#     'scheduler_step_size': 7,\n",
        "#     'gamma': 0.1,\n",
        "#     'num_epochs': 1,\n",
        "#     'patience': 10\n",
        "# }\n",
        "\n",
        "# trained_models = train_model_kfold(model_name, model, preprocess, k=5, hyperparameters=hyperparameters)\n",
        "\n",
        "# completed_model_sets.append(\n",
        "#     {\n",
        "#         'name': model_name,\n",
        "#         'preprocess': preprocess,\n",
        "#         'models': trained_models\n",
        "#     }\n",
        "# )"
      ],
      "metadata": {
        "id": "xlByrqV-efeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SqueezeNet1.0"
      ],
      "metadata": {
        "id": "bMDvAuDt1w-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_name = 'SqueezeNet1.0'\n",
        "# weights = models.SqueezeNet1_0_Weights.IMAGENET1K_V1\n",
        "# model = models.squeezenet1_0(weights=weights)\n",
        "# preprocess = weights.transforms(antialias=None)\n",
        "\n",
        "# model.classifier[-1] = nn.Linear(model.classifier[-1].in_features, len(all_labels))\n",
        "# model = model.to(device)\n",
        "\n",
        "# crop_size = preprocess.crop_size[0]\n",
        "# input_size = (3, crop_size, crop_size)\n",
        "# summary(model, input_size)"
      ],
      "metadata": {
        "id": "EeCLnICb1w-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters = {\n",
        "#     'loss_function': nn.CrossEntropyLoss(),\n",
        "#     'learning_rate': 0.001,\n",
        "#     'momentum': 0.9,\n",
        "#     'scheduler_step_size': 7,\n",
        "#     'gamma': 0.1,\n",
        "#     'num_epochs': 1,\n",
        "#     'patience': 10\n",
        "# }\n",
        "\n",
        "# trained_models = train_model_kfold(model_name, model, preprocess, k=5, hyperparameters=hyperparameters)\n",
        "\n",
        "# completed_model_sets.append(\n",
        "#     {\n",
        "#         'name': model_name,\n",
        "#         'preprocess': preprocess,\n",
        "#         'models': trained_models\n",
        "#     }\n",
        "# )"
      ],
      "metadata": {
        "id": "359fIh7Q1w-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ShuffleNetV2"
      ],
      "metadata": {
        "id": "QNmxqmUE1yDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'ShuffleNetV2'\n",
        "weights = models.ShuffleNet_V2_X1_0_Weights.IMAGENET1K_V1\n",
        "model = models.shufflenet_v2_x1_0(weights=weights)\n",
        "preprocess = weights.transforms(antialias=None)\n",
        "\n",
        "model.fc = nn.Linear(model.fc.in_features, len(all_labels))\n",
        "model = model.to(device)\n",
        "\n",
        "crop_size = preprocess.crop_size[0]\n",
        "input_size = (3, crop_size, crop_size)\n",
        "summary(model, input_size)"
      ],
      "metadata": {
        "id": "n09h1U8t1yDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters = {\n",
        "#     'loss_function': nn.CrossEntropyLoss(),\n",
        "#     'learning_rate': 0.001,\n",
        "#     'momentum': 0.9,\n",
        "#     'scheduler_step_size': 7,\n",
        "#     'gamma': 0.1,\n",
        "#     'num_epochs': 1,\n",
        "#     'patience': 10\n",
        "# }\n",
        "\n",
        "# trained_models = train_model_kfold(model_name, model, preprocess, k=5, hyperparameters=hyperparameters)\n",
        "\n",
        "# completed_model_sets.append(\n",
        "#     {\n",
        "#         'name': model_name,\n",
        "#         'preprocess': preprocess,\n",
        "#         'models': trained_models\n",
        "#     }\n",
        "# )"
      ],
      "metadata": {
        "id": "8kOctZG31yDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet-152"
      ],
      "metadata": {
        "id": "mBkV8ev83noA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'ResNet-152'\n",
        "weights = models.ResNet152_Weights.IMAGENET1K_V2\n",
        "model = models.resnet152(weights=weights)\n",
        "preprocess = weights.transforms(antialias=None)\n",
        "\n",
        "model.fc = nn.Linear(model.fc.in_features, len(all_labels))\n",
        "model = model.to(device)\n",
        "\n",
        "crop_size = preprocess.crop_size[0]\n",
        "input_size = (3, crop_size, crop_size)\n",
        "summary(model, input_size)"
      ],
      "metadata": {
        "id": "TYhuL_hm3noK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters = {\n",
        "#     'loss_function': nn.CrossEntropyLoss(),\n",
        "#     'learning_rate': 0.001,\n",
        "#     'momentum': 0.9,\n",
        "#     'scheduler_step_size': 7,\n",
        "#     'gamma': 0.1,\n",
        "#     'num_epochs': 1,\n",
        "#     'patience': 10\n",
        "# }\n",
        "\n",
        "# trained_models = train_model_kfold(model_name, model, preprocess, k=5, hyperparameters=hyperparameters)\n",
        "\n",
        "# completed_model_sets.append(\n",
        "#     {\n",
        "#         'name': model_name,\n",
        "#         'preprocess': preprocess,\n",
        "#         'models': trained_models\n",
        "#     }\n",
        "# )"
      ],
      "metadata": {
        "id": "bzLPiPxk3noK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Models"
      ],
      "metadata": {
        "id": "dVJzKiNKp44M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup DataFrame"
      ],
      "metadata": {
        "id": "z7xNCiwNzV26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_percentage(x):\n",
        "    return f'{x*100:.3f}%'\n",
        "\n",
        "def from_percentage(percentage):\n",
        "    percentage = percentage.rstrip('%')\n",
        "    try:\n",
        "        decimal = float(percentage) / 1000\n",
        "        return decimal\n",
        "    except ValueError:\n",
        "        raise ValueError(\"Invalid Format\")\n",
        "\n",
        "k = 5\n",
        "results_df = pd.DataFrame(columns=['Model'] + [f'Test-{i+1} Accuracy' for i in range(k)] + ['Average Accuracy'])"
      ],
      "metadata": {
        "id": "SfO-sxcqzZZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility Functions"
      ],
      "metadata": {
        "id": "jni2xXNqqDzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_outputs(model, preprocess, dataloader):\n",
        "    targets = []\n",
        "    predictions = []\n",
        "    probabilities_list = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch_image, batch_target in dataloader:\n",
        "            batch_image = [preprocess(image) for image in batch_image]\n",
        "            batch_image = torch.stack(batch_image)\n",
        "            batch_image = batch_image.to(device)\n",
        "            batch_target = batch_target.to(device)\n",
        "\n",
        "            batch_probabilities = model(batch_image)\n",
        "            _, batch_prediction = torch.max(batch_probabilities, 1)\n",
        "\n",
        "            targets.extend(batch_target.cpu().numpy())\n",
        "            predictions.extend(batch_prediction.cpu().numpy())\n",
        "            probabilities_list.extend(batch_probabilities.detach().cpu().numpy())\n",
        "\n",
        "    return targets, predictions, probabilities_list"
      ],
      "metadata": {
        "id": "q2S7xVy8fQHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_targets(targets):\n",
        "    target_attributes = {'Label': [], 'Vegetable': [], 'Quality': []}\n",
        "\n",
        "    for target in targets:\n",
        "        label = all_labels[target]\n",
        "        vegetable, quality = parse_label(label)\n",
        "\n",
        "        target_attributes['Label'].append(label)\n",
        "        target_attributes['Vegetable'].append(vegetable)\n",
        "        target_attributes['Quality'].append(quality)\n",
        "\n",
        "    return target_attributes\n",
        "\n",
        "def parse_probabilities(probabilities):\n",
        "    label_probabilities = {}\n",
        "    vegetable_probabilities = {}\n",
        "    quality_probabilities = {}\n",
        "\n",
        "    for label in all_labels: label_probabilities[label] = 0\n",
        "    for vegetable in all_vegetables: vegetable_probabilities[vegetable] = 0\n",
        "    for quality in all_qualities: quality_probabilities[quality] = 0\n",
        "\n",
        "    for i, value in enumerate(probabilities):\n",
        "        label = all_labels[i]\n",
        "        vegetable, quality = parse_label(label)\n",
        "\n",
        "        label_probabilities[label] += value\n",
        "        vegetable_probabilities[vegetable] += value\n",
        "        quality_probabilities[quality] += value\n",
        "\n",
        "    return {\n",
        "        'Label': label_probabilities,\n",
        "        'Vegetable': vegetable_probabilities,\n",
        "        'Quality': quality_probabilities\n",
        "    }\n",
        "\n",
        "def parse_probabilities_list(probabilities_list):\n",
        "    probabilities_attributes = {'Label': [], 'Vegetable': [], 'Quality': []}\n",
        "\n",
        "    for probabilities in probabilities_list:\n",
        "        parsed_probabilities = parse_probabilities(probabilities)\n",
        "        probabilities_attributes['Label'].append(parsed_probabilities['Label'])\n",
        "        probabilities_attributes['Vegetable'].append(parsed_probabilities['Vegetable'])\n",
        "        probabilities_attributes['Quality'].append(parsed_probabilities['Quality'])\n",
        "\n",
        "    return probabilities_attributes\n",
        "\n",
        "def filter_label(label):\n",
        "    label = label.replace(' - ', ' ')\n",
        "    words = label.split()\n",
        "\n",
        "    pair_of_words = [f'{words[i]} {words[i+1]}' if i < len(words) - 1 else words[i] for i in range(0, len(words), 2)]\n",
        "    filtered_label = '\\n'.join(pair_of_words)\n",
        "\n",
        "    return filtered_label\n",
        "\n",
        "def filter_labels_list(labels_list):\n",
        "    filtered_labels_list = []\n",
        "    for label in labels_list: filtered_labels_list.append(filter_label(label))\n",
        "\n",
        "    return filtered_labels_list\n",
        "\n",
        "def filter_probabilities_list(probabilities_list):\n",
        "    filtered_probabilities_list = []\n",
        "\n",
        "    for probabilities in probabilities_list:\n",
        "        filtered_probabilities = {}\n",
        "\n",
        "        for key, value in probabilities.items():\n",
        "            filtered_key = filter_label(key)\n",
        "            filtered_probabilities[filtered_key] = value\n",
        "\n",
        "        filtered_probabilities_list.append(filtered_probabilities)\n",
        "\n",
        "    return filtered_probabilities_list"
      ],
      "metadata": {
        "id": "29IPIgh8p8oD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_auc_roc(targets, probabilities):\n",
        "    sorted_indices = np.argsort(np.array(probabilities))[::-1]\n",
        "    sorted_targets = np.array(targets)[sorted_indices]\n",
        "\n",
        "    num_positive = np.sum(sorted_targets)\n",
        "    num_negative = len(sorted_targets) - num_positive\n",
        "\n",
        "    if num_positive == 0 or num_negative == 0: return 0.0\n",
        "\n",
        "    running_positive_count = 0\n",
        "    auc_sum = 0.0\n",
        "\n",
        "    for i in range(len(sorted_targets)):\n",
        "        if sorted_targets[i] == 1: running_positive_count += 1\n",
        "        else: auc_sum += running_positive_count\n",
        "\n",
        "    return auc_sum / (num_positive * num_negative)"
      ],
      "metadata": {
        "id": "7KHQ1-_OJz-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_metrics(confusion_matrix, targets, probabilities, labels):\n",
        "    precision_values = []\n",
        "    recall_values = []\n",
        "    f1_score_values = []\n",
        "    specificity_values = []\n",
        "    auc_roc_values = []\n",
        "\n",
        "    for i, label in enumerate(labels):\n",
        "        tp = confusion_matrix[i, i]\n",
        "        fp = np.sum(confusion_matrix[:, i]) - tp\n",
        "        fn = np.sum(confusion_matrix[i, :]) - tp\n",
        "        tn = np.sum(confusion_matrix) - tp - fp - fn\n",
        "\n",
        "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "\n",
        "        class_targets = np.where(np.array(targets) == label, 1, 0)\n",
        "        class_probabilities = [probability[label] for probability in probabilities]\n",
        "        auc_roc = calculate_auc_roc(class_targets, class_probabilities)\n",
        "\n",
        "        precision_values.append(precision)\n",
        "        recall_values.append(recall)\n",
        "        f1_score_values.append(f1_score)\n",
        "        specificity_values.append(specificity)\n",
        "        auc_roc_values.append(auc_roc)\n",
        "\n",
        "    metrics_df = pd.DataFrame(index=['Precision', 'Recall', 'F1 Score', 'Specificity', 'AUC-ROC'], columns=labels)\n",
        "    metrics_df.loc['Precision'] = precision_values\n",
        "    metrics_df.loc['Recall'] = recall_values\n",
        "    metrics_df.loc['F1 Score'] = f1_score_values\n",
        "    metrics_df.loc['Specificity'] = specificity_values\n",
        "    metrics_df.loc['AUC-ROC'] = auc_roc_values\n",
        "\n",
        "    return metrics_df\n",
        "\n",
        "def generate_confusion_matrix(targets, predictions, probabilities, labels):\n",
        "    targets = filter_labels_list(targets)\n",
        "    predictions = filter_labels_list(predictions)\n",
        "    labels = filter_labels_list(labels)\n",
        "    probabilities = filter_probabilities_list(probabilities)\n",
        "\n",
        "    label_indices = {label: index for index, label in enumerate(labels)}\n",
        "    num_labels = len(labels)\n",
        "\n",
        "    confusion_matrix = np.zeros((num_labels, num_labels), dtype=np.int32)\n",
        "\n",
        "    for target, prediction in zip(targets, predictions):\n",
        "        target_index = label_indices[target]\n",
        "        prediction_index = label_indices[prediction]\n",
        "        confusion_matrix[target_index, prediction_index] += 1\n",
        "\n",
        "    confusion_df = pd.DataFrame(confusion_matrix, index=labels, columns=labels)\n",
        "    correct_count = np.diag(confusion_matrix).sum()\n",
        "    metrics_df = calculate_metrics(confusion_matrix, targets, probabilities ,labels).astype(float).round(3)\n",
        "\n",
        "    return confusion_df, metrics_df, correct_count\n",
        "\n",
        "def display_matrices(model_name, test_index, confusion_matrices, metrics_tables, correct_counts, total_count):\n",
        "    matrices = [\n",
        "        confusion_matrices['Label'], metrics_tables['Label'],\n",
        "        confusion_matrices['Vegetable'], metrics_tables['Vegetable'],\n",
        "        confusion_matrices['Quality'], metrics_tables['Quality']\n",
        "    ]\n",
        "\n",
        "    plt.figure(figsize=(25, 50))\n",
        "    colspans = [2, 2, 1, 1, 1, 1]\n",
        "    rowspans = [2, 1, 1, 1, 1, 1]\n",
        "    plot_arrangements = [(0, 0),\n",
        "        (rowspans[0], 0),\n",
        "        (rowspans[0]+rowspans[1], 0),\n",
        "        (rowspans[0]+rowspans[1]+rowspans[2], 0),\n",
        "        (rowspans[0]+rowspans[1], 1),\n",
        "        (rowspans[0]+rowspans[1]+rowspans[2], 1)\n",
        "    ]\n",
        "    contexts = ['Label', 'Vegetable', 'Quality']\n",
        "\n",
        "    for i, plot_arrangement in enumerate(plot_arrangements):\n",
        "        plt.subplot2grid((5, 2), plot_arrangement, colspan=colspans[i], rowspan=rowspans[i])\n",
        "        heatmap = sns.heatmap(matrices[i], annot=True, fmt='g', cmap='Blues', cbar=False, annot_kws={\"fontsize\": 16})\n",
        "        heatmap.set_xticklabels(heatmap.get_xticklabels(), fontsize=16, rotation=45)\n",
        "        heatmap.set_yticklabels(heatmap.get_yticklabels(), fontsize=16, rotation=0)\n",
        "\n",
        "        if i % 2 == 0:\n",
        "            plt.xlabel('Predicted', fontsize=16)\n",
        "            plt.ylabel('Actual', fontsize=16)\n",
        "            plt.title(f'Confusion Matrix ({contexts[i//2]}), Accuracy: {correct_counts[contexts[i//2]]}/{total_count} = {correct_counts[contexts[i//2]] / total_count:.2%}', fontsize=18)\n",
        "        else:\n",
        "            plt.title(f'Metrics ({contexts[i//2]})', fontsize=18)\n",
        "\n",
        "    plt.suptitle(f'Test-{test_index + 1} Results: {model_name}', fontsize=24)\n",
        "    plt.tight_layout(pad=4.0)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "cdOh5FYz0PDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(test_index, model_name, model, preprocess, dataloader):\n",
        "    since = time.time()\n",
        "\n",
        "    print(f'Evaluating {model_name} on Test {test_index+1}')\n",
        "    print('-' * 20)\n",
        "    print()\n",
        "\n",
        "    targets, predictions, probabilities_list = get_outputs(model, preprocess, dataloader)\n",
        "    total_count = len(targets)\n",
        "\n",
        "    target_attributes = parse_targets(targets)\n",
        "    predicted_attributes = parse_targets(predictions)\n",
        "    probability_attributes = parse_probabilities_list(probabilities_list)\n",
        "\n",
        "    all_values = {\n",
        "        'Label': all_labels,\n",
        "        'Vegetable': all_vegetables,\n",
        "        'Quality': all_qualities\n",
        "    }\n",
        "\n",
        "    contexts = ['Label', 'Vegetable', 'Quality']\n",
        "    confusion_matrices = {}\n",
        "    metrics_tables = {}\n",
        "    correct_counts = {}\n",
        "\n",
        "    for context in contexts:\n",
        "        print(f'Matching {context}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        target_values = target_attributes[context]\n",
        "        predicted_values = predicted_attributes[context]\n",
        "        probability_values = probability_attributes[context]\n",
        "\n",
        "        confusion_matrices[context], metrics_tables[context], correct_counts[context] = generate_confusion_matrix(\n",
        "            target_values,\n",
        "            predicted_values,\n",
        "            probability_values,\n",
        "            all_values[context]\n",
        "        )\n",
        "\n",
        "    print('Generating Confusion Matrices')\n",
        "    print('-' * 10)\n",
        "    display_matrices(model_name, test_index, confusion_matrices, metrics_tables, correct_counts, total_count)\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Evaluation complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print()\n",
        "\n",
        "    return correct_counts['Label']/total_count"
      ],
      "metadata": {
        "id": "DYwGZSx_0PQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Evaluation"
      ],
      "metadata": {
        "id": "DdOANpd6qhIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for model_set in completed_model_sets:\n",
        "    model_name = model_set['name']\n",
        "\n",
        "    row = {'Model': model_name}\n",
        "    for test_index, model in enumerate(model_set['models']):\n",
        "        acc = evaluate(test_index, model_name, model, model_set['preprocess'], dataloaders[test_index]['Test'])\n",
        "        row[f'Test-{test_index + 1} Accuracy'] = acc\n",
        "\n",
        "    results_df = pd.concat([results_df, pd.DataFrame(row, index=[0])], ignore_index=True)"
      ],
      "metadata": {
        "id": "2eNe9ic2bC4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# View Results"
      ],
      "metadata": {
        "id": "YeNFbINf0XbU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate Average Accuracy"
      ],
      "metadata": {
        "id": "EA0Jquatfl2j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weighted_average_accuracies = []\n",
        "for index, row in results_df.iterrows():\n",
        "    weights = [len(dataloader['Test']) for dataloader in dataloaders]\n",
        "    average_accuracy = row.iloc[1:-1].dot(weights) / sum(weights)\n",
        "    weighted_average_accuracies.append(average_accuracy)\n",
        "\n",
        "results_df['Average Accuracy'] = weighted_average_accuracies"
      ],
      "metadata": {
        "id": "eXZM5j5CfpNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display Results"
      ],
      "metadata": {
        "id": "bh6lJv8sftqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_df['Average Accuracy'] = results_df['Average Accuracy'].map(to_percentage)\n",
        "for i in range(k):\n",
        "    results_df[f'Test-{i+1} Accuracy'] = results_df[f'Test-{i+1} Accuracy'].map(to_percentage)\n",
        "\n",
        "display(results_df)\n",
        "\n",
        "results_df['Average Accuracy'] = results_df['Average Accuracy'].map(from_percentage)\n",
        "for i in range(k):\n",
        "    results_df[f'Test-{i+1} Accuracy'] = results_df[f'Test-{i+1} Accuracy'].map(from_percentage)"
      ],
      "metadata": {
        "id": "KYCskx6gR5oV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Best Model Analysis (Simple)"
      ],
      "metadata": {
        "id": "ngriottGY7-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select Best Model"
      ],
      "metadata": {
        "id": "dNFEvNlznWyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_row = results_df[results_df['Average Accuracy'] == results_df['Average Accuracy'].max()]\n",
        "best_model_name = best_model_row['Model'].values[0]\n",
        "best_model_index = completed_model_sets.index(next(model_set for model_set in completed_model_sets if model_set['name'] == best_model_name))\n",
        "best_model_set = completed_model_sets[best_model_index]"
      ],
      "metadata": {
        "id": "kmHJrHtHnQ1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility Functions"
      ],
      "metadata": {
        "id": "LIgcr7y9b2a1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_misclassifications(model, preprocess, dataloader):\n",
        "    vegetable_mismatch_count = 0\n",
        "    quality_mismatch_count = 0\n",
        "\n",
        "    misclassifications = []\n",
        "    seen_pairs = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch_image, batch_target in dataloader:\n",
        "            batch_image = [preprocess(image) for image in batch_image]\n",
        "            batch_image = torch.stack(batch_image)\n",
        "            batch_image = batch_image.to(device)\n",
        "            batch_target = batch_target.to(device)\n",
        "\n",
        "            batch_probabilities = model(batch_image)\n",
        "            _, batch_prediction = torch.max(batch_probabilities, 1)\n",
        "\n",
        "            misclassified_indices = (batch_prediction != batch_target).nonzero().view(-1)\n",
        "\n",
        "            for index in misclassified_indices:\n",
        "                input_image = batch_image[index].cpu()\n",
        "                target_attribute = parse_targets([batch_target[index].item()])\n",
        "                predicted_attribute = parse_targets([batch_prediction[index].item()])\n",
        "\n",
        "                label_pair = target_attribute['Label'], predicted_attribute['Label']\n",
        "                if label_pair in seen_pairs: continue\n",
        "                seen_pairs.append(label_pair)\n",
        "\n",
        "                if (target_attribute['Vegetable'] != predicted_attribute['Vegetable']) and \\\n",
        "                   (target_attribute['Quality'] != predicted_attribute['Quality']): pass\n",
        "\n",
        "                elif target_attribute['Vegetable'] != predicted_attribute['Vegetable']:\n",
        "                    if vegetable_mismatch_count >= 5: continue\n",
        "\n",
        "                elif target_attribute['Quality'] != predicted_attribute['Quality']:\n",
        "                    if quality_mismatch_count >= 5: continue\n",
        "\n",
        "                if target_attribute['Vegetable'] != predicted_attribute['Vegetable']: vegetable_mismatch_count += 1\n",
        "                if target_attribute['Quality'] != predicted_attribute['Quality']: quality_mismatch_count += 1\n",
        "\n",
        "                misclassifications.append({\n",
        "                    'image': input_image,\n",
        "                    'target': target_attribute,\n",
        "                    'prediction': predicted_attribute\n",
        "                })\n",
        "\n",
        "                if len(misclassifications) == 10: return misclassifications\n",
        "\n",
        "    return misclassifications"
      ],
      "metadata": {
        "id": "o5rfxEx8Xf1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_misclassifications(model_name, test_index, misclassifications):\n",
        "    num_misclassifications = len(misclassifications)\n",
        "    num_cols = 5\n",
        "    num_rows = math.ceil(num_misclassifications / num_cols)\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 4*num_rows))\n",
        "\n",
        "    for i, misclassification in enumerate(misclassifications):\n",
        "        row = i // num_cols\n",
        "        col = i % num_cols\n",
        "\n",
        "        input_image = misclassification['image'].numpy().transpose(1, 2, 0)\n",
        "        input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
        "        target_label = misclassification['target']['Label']\n",
        "        predicted_label = misclassification['prediction']['Label']\n",
        "\n",
        "        ax = axes[row, col] if num_rows > 1 else axes[col]\n",
        "        ax.imshow(input_image)\n",
        "        ax.set_title(f'Target: {target_label}\\nPredicted: {predicted_label}',\n",
        "                     fontsize=9, pad=9)\n",
        "        ax.axis('off')\n",
        "\n",
        "    for i in range(len(misclassifications), num_rows * num_cols):\n",
        "        row = i // num_cols\n",
        "        col = i % num_cols\n",
        "\n",
        "        ax = axes[row, col] if num_rows > 1 else axes[col]\n",
        "        ax.axis('off')\n",
        "\n",
        "    plt.suptitle(f'Test-{test_index + 1}: {model_name}', fontsize=24)\n",
        "    plt.tight_layout(h_pad=2)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "C2Ivl9Zqasng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Analysis"
      ],
      "metadata": {
        "id": "wBEoMoOQb7Uz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_set = best_model_set\n",
        "model_name = model_set['name']\n",
        "\n",
        "for test_index, model in enumerate(model_set['models']):\n",
        "    misclassifications = get_misclassifications(model, model_set['preprocess'], dataloaders[test_index]['Test'])\n",
        "    display_misclassifications(model_name, test_index, misclassifications)"
      ],
      "metadata": {
        "id": "SPsN9iK3Y-gH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Best Model Analysis (Complex)"
      ],
      "metadata": {
        "id": "YtG6O8rzwacn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select Best Model"
      ],
      "metadata": {
        "id": "t4mNvUIzwaco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_row = results_df[results_df['Average Accuracy'] == results_df['Average Accuracy'].max()]\n",
        "best_model_name = best_model_row['Model'].values[0]\n",
        "best_model_index = completed_model_sets.index(next(model_set for model_set in completed_model_sets if model_set['name'] == best_model_name))\n",
        "best_model_set = completed_model_sets[best_model_index]"
      ],
      "metadata": {
        "id": "N7pQGZWSwacp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define GradCAM Class"
      ],
      "metadata": {
        "id": "m8BkIYxQwngg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage import io\n",
        "from torchvision import transforms\n",
        "from torch.autograd import Function\n",
        "import cv2\n",
        "\n",
        "class GradCam:\n",
        "    def __init__(self, model, target_layer):\n",
        "        self.model = model\n",
        "        self.target_layer = target_layer\n",
        "        self.gradient = None\n",
        "        self.activations = None\n",
        "\n",
        "        self.hook_handles = []\n",
        "        for module in self.model.named_modules():\n",
        "            if module[0] == self.target_layer:\n",
        "                self.hook_handles.append(module[1].register_backward_hook(self.save_gradient))\n",
        "            elif 'relu' in module[0]:\n",
        "                self.hook_handles.append(module[1].register_forward_hook(self.save_activation))\n",
        "\n",
        "    def save_gradient(self, module, grad_input, grad_output):\n",
        "        self.gradient = grad_output[0]\n",
        "\n",
        "    def save_activation(self, module, input, output):\n",
        "        self.activations = output\n",
        "\n",
        "    def __call__(self, x):\n",
        "        x.requires_grad_()\n",
        "        self.model.zero_grad()\n",
        "        output = self.model(x)\n",
        "        output.backward(gradient=torch.ones_like(output))\n",
        "        grad_values = self.gradient.mean(dim=(2, 3), keepdim=True)\n",
        "        cam = torch.sum(self.activations * grad_values, dim=1, keepdim=True)\n",
        "        cam = F.relu(cam)\n",
        "        cam = F.interpolate(cam, size=(x.size(2), x.size(3)), mode=\"bilinear\", align_corners=False)\n",
        "        cam = cam.squeeze()\n",
        "        cam = cam.detach().cpu().numpy()\n",
        "        cam = np.maximum(cam, 0)\n",
        "        cam = (cam - np.min(cam)) / (np.max(cam) - np.min(cam))\n",
        "        return cam"
      ],
      "metadata": {
        "id": "3gFAVwN2wgeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility Functions"
      ],
      "metadata": {
        "id": "UKIIySsAwacp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_misclassifications(model, preprocess, dataloader):\n",
        "    vegetable_mismatch_count = 0\n",
        "    quality_mismatch_count = 0\n",
        "\n",
        "    misclassifications = []\n",
        "    seen_pairs = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch_image, batch_target in dataloader:\n",
        "            batch_image = [preprocess(image) for image in batch_image]\n",
        "            batch_image = torch.stack(batch_image)\n",
        "            batch_image = batch_image.to(device)\n",
        "            batch_target = batch_target.to(device)\n",
        "\n",
        "            batch_probabilities = model(batch_image)\n",
        "            _, batch_prediction = torch.max(batch_probabilities, 1)\n",
        "\n",
        "            misclassified_indices = (batch_prediction != batch_target).nonzero().view(-1)\n",
        "\n",
        "            for index in misclassified_indices:\n",
        "                input_image = batch_image[index].cpu()\n",
        "                target_attribute = parse_targets([batch_target[index].item()])\n",
        "                predicted_attribute = parse_targets([batch_prediction[index].item()])\n",
        "\n",
        "                label_pair = target_attribute['Label'], predicted_attribute['Label']\n",
        "                if label_pair in seen_pairs: continue\n",
        "                seen_pairs.append(label_pair)\n",
        "\n",
        "                if (target_attribute['Vegetable'] != predicted_attribute['Vegetable']) and \\\n",
        "                   (target_attribute['Quality'] != predicted_attribute['Quality']): pass\n",
        "\n",
        "                elif target_attribute['Vegetable'] != predicted_attribute['Vegetable']:\n",
        "                    if vegetable_mismatch_count >= 5: continue\n",
        "\n",
        "                elif target_attribute['Quality'] != predicted_attribute['Quality']:\n",
        "                    if quality_mismatch_count >= 5: continue\n",
        "\n",
        "                if target_attribute['Vegetable'] != predicted_attribute['Vegetable']: vegetable_mismatch_count += 1\n",
        "                if target_attribute['Quality'] != predicted_attribute['Quality']: quality_mismatch_count += 1\n",
        "\n",
        "                misclassifications.append({\n",
        "                    'image': input_image,\n",
        "                    'target': target_attribute,\n",
        "                    'prediction': predicted_attribute\n",
        "                })\n",
        "\n",
        "                if len(misclassifications) == 10: return misclassifications\n",
        "\n",
        "    return misclassifications"
      ],
      "metadata": {
        "id": "MO82lVMCwacq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_misclassifications(model, model_name, test_index, misclassifications):\n",
        "    num_misclassifications = len(misclassifications)\n",
        "    fig, axes = plt.subplots(num_misclassifications, 3, figsize=(15, 4*num_misclassifications))\n",
        "\n",
        "    target_layer = model.features.denseblock4.denselayer16.conv2\n",
        "    grad_cam = GradCam(model, target_layer)\n",
        "\n",
        "    for i, misclassification in enumerate(misclassifications):\n",
        "        input_image = misclassification['image'].numpy().transpose(1, 2, 0)\n",
        "        input_image = (input_image - input_image.min()) / (input_image.max() - input_image.min())\n",
        "        target_label = misclassification['target']['Label']\n",
        "        predicted_label = misclassification['prediction']['Label']\n",
        "\n",
        "        ax1 = axes[i, 0]\n",
        "        ax1.imshow(input_image)\n",
        "        ax1.set_title(f'Target: {target_label}\\nPredicted: {predicted_label}',\n",
        "                      fontsize=9, pad=9)\n",
        "        ax1.axis('off')\n",
        "\n",
        "        input_tensor = torch.tensor(input_image.transpose(2, 0, 1)).unsqueeze(0).to(device)\n",
        "        cam = grad_cam(input_tensor)\n",
        "        cam = cv2.resize(cam, (input_image.shape[1], input_image.shape[0]))\n",
        "        heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET)\n",
        "\n",
        "        ax2 = axes[i, 1]\n",
        "        ax2.imshow(heatmap)\n",
        "        ax2.set_title('Grad-CAM Heatmap', fontsize=9, pad=9)\n",
        "        ax2.axis('off')\n",
        "\n",
        "        blended_image = cv2.addWeighted(input_image, 0.7, heatmap, 0.3, 0)\n",
        "\n",
        "        ax3 = axes[i, 2]\n",
        "        ax3.imshow(blended_image)\n",
        "        ax3.set_title('Original + Grad-CAM', fontsize=9, pad=9)\n",
        "        ax3.axis('off')\n",
        "\n",
        "    plt.suptitle(f'Test-{test_index + 1}: {model_name}', fontsize=24)\n",
        "    plt.tight_layout(h_pad=2)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "YxSDLgFPwacq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Analysis"
      ],
      "metadata": {
        "id": "MguLYxqRwacq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_set = best_model_set\n",
        "model_name = model_set['name']\n",
        "\n",
        "for test_index, model in enumerate(model_set['models']):\n",
        "    misclassifications = get_misclassifications(model, model_set['preprocess'], dataloaders[test_index]['Test'])\n",
        "    display_misclassifications(model, model_name, test_index, misclassifications)"
      ],
      "metadata": {
        "id": "2CumW7Vzwacr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}